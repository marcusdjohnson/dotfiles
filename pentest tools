
git clone https://github.com/aboul3la/Sublist3r.git
Short Form	Long Form	Description
-d	--domain	Domain name to enumerate subdomains of
-b	--bruteforce	Enable the subbrute bruteforce module
-p	--ports	Scan the found subdomains against specific tcp ports
-v	--verbose	Enable the verbose mode and display results in realtime
-t	--threads	Number of threads to use for subbrute bruteforce
-e	--engines	Specify a comma-separated list of search engines
-o	--output	Save the results to text file
-h	--help	show the help message and exit
Examples
To list all the basic options and switches use -h switch:
python sublist3r.py -h

To enumerate subdomains of specific domain:
python sublist3r.py -d example.com

To enumerate subdomains of specific domain and show only subdomains which have open ports 80 and 443 :
python sublist3r.py -d example.com -p 80,443

To enumerate subdomains of specific domain and show the results in realtime:
python sublist3r.py -v -d example.com

To enumerate subdomains and enable the bruteforce module:
python sublist3r.py -b -d example.com

To enumerate subdomains and use specific engines such Google, Yahoo and Virustotal engines
python sublist3r.py -e google,yahoo,virustotal -d example.com

git clone https://github.com/v0re/dirb.git
DIRB takes 2 main parameters, the base URL for testing and a list of wordlist 
files used for the attack. Example:

	$ ./dirb.exe http://www.test.org/ common.txt 


The URL must be a valid standard URL and the wordlists are simple text files 
with a word by line. It is also possible to scan subdirectories directly:

	$ ./dirb.exe http://www.test.org/html/ common.txt
	
	
For SSL simply include the HTTPS url:

	$ ./dirb.exe https://www.test.org/ common.txt -i


You can use multiple wordfiles at a time this way (separated by comma):

	$ ./dirb.exe https://www.test.org/ common.txt,spanish.txt,names.txt 
	

You can append different extensions to the probed words, by using the -x or 
the -X option:

	$ ./dirb.exe https://www.test.org/ common.txt -X .html,.asp,.jsp,,

	$ ./dirb.exe https://www.test.org/ common.txt -x extensions.txt
	
	
Examples
--------

+ Scan a webserver for common directories/files: (without using file 
extensions)
	
	$ ./src/dirb.exe http://www.test.org/ wordlists/common.txt	


+ Scan a webserver for common directories/files: (search for PHP and HTML 
files)

	$ ./src/dirb.exe http://www.test.org/ wordlists/common.txt -X .php,.html	


+ When a file is found, try different variations: (~, .old, etc...)

	$ ./src/dirb.exe http://www.test.org/ wordlists/common.txt -X .php,.html -M ~,.tmp,.old,.backup,.test
	

git clone https://github.com/vysecurity/DomLink.git
DomLink is a tool that uses a domain name to discover organisation name and associated e-mail address to then find further associated domains.

This is useful for bug bounty and red team engagements where you need to discover more domains associated with the target.

python domlink.py -D target.com -o target.out.txt


git clone https://github.com/blechschmidt/massdns.git
Usage
Usage: ./bin/massdns [options] [domainlist]
  -b  --bindto           Bind to IP address and port. (Default: 0.0.0.0:0)
      --busy-poll        Use busy-wait polling instead of epoll.
  -c  --resolve-count    Number of resolves for a name before giving up. (Default: 50)
      --drop-group       Group to drop privileges to when running as root. (Default: nogroup)
      --drop-user        User to drop privileges to when running as root. (Default: nobody)
      --flush            Flush the output file whenever a response was received.
  -h  --help             Show this help.
  -i  --interval         Interval in milliseconds to wait between multiple resolves of the same
                         domain. (Default: 500)
  -l  --error-log        Error log file path. (Default: /dev/stderr)
      --norecurse        Use non-recursive queries. Useful for DNS cache snooping.
  -o  --output           Flags for output formatting.
      --predictable      Use resolvers incrementally. Useful for resolver tests.
      --processes        Number of processes to be used for resolving. (Default: 1)
  -q  --quiet            Quiet mode.
      --rcvbuf           Size of the receive buffer in bytes.
      --retry            Unacceptable DNS response codes. (Default: REFUSED)
  -r  --resolvers        Text file containing DNS resolvers.
      --root             Do not drop privileges when running as root. Not recommended.
  -s  --hashmap-size     Number of concurrent lookups. (Default: 10000)
      --sndbuf           Size of the send buffer in bytes.
      --sticky           Do not switch the resolver when retrying.
      --socket-count     Socket count per process. (Default: 1)
  -t  --type             Record type to be resolved. (Default: A)
      --verify-ip        Verify IP addresses of incoming replies.
  -w  --outfile          Write to the specified output file instead of standard output.

Output flags:
  S - simple text output
  F - full text output
  B - binary output
  J - ndjson output
This overview may be incomplete. For more options, especially concerning output formatting, use --help.

Example
Resolve all AAAA records from domains within domains.txt using the resolvers within resolvers.txt in lists and store the results within results.txt:

$ ./bin/massdns -r lists/resolvers.txt -t AAAA domains.txt > results.txt
This is equivalent to:

$ ./bin/massdns -r lists/resolvers.txt -t AAAA -w results.txt domains.txt
Example output
By default, MassDNS will output response packets in text format which looks similar to the following:

;; Server: 77.41.229.2:53
;; Size: 93
;; Unix time: 1513458347
;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 51298
;; flags: qr rd ra ; QUERY: 1, ANSWER: 1, AUTHORITY: 2, ADDITIONAL: 0

;; QUESTION SECTION:
example.com. IN A

;; ANSWER SECTION:
example.com. 45929 IN A 93.184.216.34

;; AUTHORITY SECTION:
example.com. 24852 IN NS b.iana-servers.net.
example.com. 24852 IN NS a.iana-servers.net.
The resolver IP address is included in order to make it easier for you to filter the output in case you detect that some resolvers produce bad results.


git clone --depth 1 https://github.com/sqlmapproject/sqlmap.git sqlmap-dev
Usage
To get a list of basic options and switches use:

python sqlmap.py -h
To get a list of all options and switches use:

python sqlmap.py -hh
You can find a sample run here. To get an overview of sqlmap capabilities, list of supported features and description of all options and switches, along with examples, you are advised to consult the user's manual.

git clone https://github.com/guelfoweb/knock.git
Sub Domain enumeration

knockpy domain.com

git clone https://github.com/nahamsec/lazyrecon.git

./lazyrecon.sh -d target.com

git clone https://github.com/tomdev/teh_s3_bucketeers.git

Requirements
https://docs.aws.amazon.com/sdk-for-java/v1/developer-guide/setup-credentials.html#setup-credentials-setting

Create an AWS account and set up your access tokens in ~/.aws/credentials like this:

[default]
aws_access_key_id = <key>
aws_secret_access_key = <secret>
Usage
You can test multiple targets at the same time, use a space as a delimiter.

./bucketeer.sh <target> <target>
A result file named results-<target>-<timestamp>.txt will be created when an accessible bucket has been found.

go get github.com/tomnomnom/waybackurls

cat domains.txt | waybackurls > urls

git clone https://github.com/maurosoria/dirsearch.git
About wordlists
Dictionaries must be text files. Each line will be processed as such, except that the special word %EXT% is used, which will generate one entry for each extension (-e | --extension) passed as an argument.

Example:

example/
example.%EXT%
Passing the extensions "asp" and "aspx" will generate the following dictionary:

example/
example.asp
example.aspx
You can also use -f | --force-extensions switch to append extensions to every word in the wordlists (like DirBuster).



git clone https://github.com/nahamsec/lazys3.git
A Ruby script to bruteforce for AWS s3 buckets using different permutations.

Usage
$ ruby lazys3.rb <COMPANY> 


git clone https://github.com/jhaddix/scripts.git

git clone https://github.com/GerbenJavado/LinkFinder.git
Usage
Short Form	Long Form	Description
-i	--input	Input a: URL, file or folder. For folders a wildcard can be used (e.g. '/*.js').
-o	--output	"cli" to print to STDOUT, otherwise where to save the HTML file Default: output.html
-r	--regex	RegEx for filtering purposes against found endpoints (e.g. ^/api/)
-d	--domain	Toggle to use when analyzing an entire domain. Enumerates over all found JS files.
-b	--burp	Toggle to use when inputting a Burp 'Save selected' file containing multiple JS files
-c	--cookies	Add cookies to the request
-h	--help	show the help message and exit
Examples
Most basic usage to find endpoints in an online JavaScript file and output the HTML results to results.html:
python linkfinder.py -i https://example.com/1.js -o results.html

CLI/STDOUT output (doesn't use jsbeautifier, which makes it very fast):
python linkfinder.py -i https://example.com/1.js -o cli

Analyzing an entire domain and its JS files:
python linkfinder.py -i https://example.com -d

Burp input (select in target the files you want to save, right click, Save selected items, feed that file as input):
python linkfinder.py -i burpfile -b

Enumerating an entire folder for JavaScript files, while looking for endpoints starting with /api/ and finally saving the results to results.html:
python linkfinder.py -i 'Desktop/*.js' -r ^/api/ -o results.html

sudo pip3 install wfuzz
Below is shown an example of wfuzz looking for common directories:

$ wfuzz -w wordlist/general/common.txt http://testphp.vulnweb.com/FUZZ
Below is shown an example of wfuzz looking for common files:

$ wfuzz -w wordlist/general/common.txt http://testphp.vulnweb.com/FUZZ.php

sudo pip3 install wafw00f
wafw00f https://example.org


sudo snap install amass
amass enum -d example.com

sudo apt intall -y masscan
# masscan -p80,8000-8100 10.0.0.0/8

# My Scan
rate =  100000.00
output-format = xml
output-status = all
output-filename = scan.xml
ports = 0-65535
range = 0.0.0.0-255.255.255.255
excludefile = exclude.txt
To use this configuration file, use the -c:

# masscan -c myscan.conf

go get github.com/OJ/gobuster

Wordlists via STDIN
Wordlists can be piped into gobuster via stdin by providing a - to the -w option:

hashcat -a 3 --stdout ?l | gobuster dir -u https://mysite.com -w -
Note: If the -w option is specified at the same time as piping from STDIN, an error will be shown and the program will terminate.

Examples
dir Mode
Command line might look like this:

gobuster dir -u https://mysite.com/path/to/folder -c 'session=123456' -t 50 -w common-files.txt -x .php,.html
Default options looks like this:

gobuster dir -u https://buffered.io -w ~/wordlists/shortlist.txt
dns Mode
Command line might look like this:

gobuster dns -d mysite.com -t 50 -w common-names.txt
Normal sample run goes like this:

gobuster dns -d google.com -w ~/wordlists/subdomains.txt
vhost Mode
Command line might look like this:

gobuster vhost -u https://mysite.com -w common-vhosts.txt
Normal sample run goes like this:

gobuster vhost -u https://mysite.com -w common-vhosts.txt


go get github.com/michenriksen/aquatone

cat targets.txt | aquatone
Usage
Command-line options:
  -chrome-path string
    	Full path to the Chrome/Chromium executable to use. By default, aquatone will search for Chrome or Chromium
  -debug
    	Print debugging information
  -http-timeout int
    	Timeout in miliseconds for HTTP requests (default 3000)
  -nmap
    	Parse input as Nmap/Masscan XML
  -out string
    	Directory to write files to (default ".")
  -ports string
    	Ports to scan on hosts. Supported list aliases: small, medium, large, xlarge (default "80,443,8000,8080,8443")
  -proxy string
    	Proxy to use for HTTP requests
  -resolution string
    	screenshot resolution (default "1440,900")
  -save-body
    	Save response bodies to files (default true)
  -scan-timeout int
    	Timeout in miliseconds for port scans (default 100)
  -screenshot-timeout int
    	Timeout in miliseconds for screenshots (default 30000)
  -session string
    	Load Aquatone session file and generate HTML report
  -silent
    	Suppress all output except for errors
  -template-path string
    	Path to HTML template to use for report
  -threads int
    	Number of concurrent threads (default number of logical CPUs)
  -version
    	Print current Aquatone version
		
Specifying ports to scan
Be default, Aquatone will scan target hosts with a small list of commonly used HTTP ports: 80, 443, 8000, 8080 and 8443. You can change this to your own list of ports with the -ports flag:

$ cat hosts.txt | aquatone -ports 80,443,3000,3001
Aquatone also supports aliases of built-in port lists to make it easier for you:

small: 80, 443
medium: 80, 443, 8000, 8080, 8443 (same as default)
large: 80, 81, 443, 591, 2082, 2087, 2095, 2096, 3000, 8000, 8001, 8008, 8080, 8083, 8443, 8834, 8888
xlarge: 80, 81, 300, 443, 591, 593, 832, 981, 1010, 1311, 2082, 2087, 2095, 2096, 2480, 3000, 3128, 3333, 4243, 4567, 4711, 4712, 4993, 5000, 5104, 5108, 5800, 6543, 7000, 7396, 7474, 8000, 8001, 8008, 8014, 8042, 8069, 8080, 8081, 8088, 8090, 8091, 8118, 8123, 8172, 8222, 8243, 8280, 8281, 8333, 8443, 8500, 8834, 8880, 8888, 8983, 9000, 9043, 9060, 9080, 9090, 9091, 9200, 9443, 9800, 9981, 12443, 16080, 18091, 18092, 20720, 28017
Example:

$ cat hosts.txt | aquatone -ports large

Nmap or Masscan
Aquatone can make a report on hosts scanned with the Nmap or Masscan portscanner. Simply feed Aquatone the XML output and give it the -nmap flag to tell it to parse the input as Nmap/Masscan XML:

$ cat scan.xml | aquatone -nmap
